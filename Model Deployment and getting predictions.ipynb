{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models\n",
    "We build a model that predicts which visitors, that visited its website on a certain day, are more likely to convert (buy something) in the next 30 days. We use the AI Notebook service of the Google Cloud Platform to develop the model.\n",
    "\n",
    "\n",
    "## Deployment and getting predictions\n",
    "We deploy our model so that it can be used to get predictions. We host the model in our Google Cloud Platform project and deploy our model using the AI Platform prediction service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-bigquery --user --use-feature=2020-resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable the required APIs\n",
    "# In order to use AI Platform, confirm that the required APIs are enabled:\n",
    "\n",
    "!gcloud services enable ml.googleapis.com\n",
    "!gcloud services enable compute.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://winged-tower-295515-bucket/...\n"
     ]
    }
   ],
   "source": [
    "# Create a storage bucket\n",
    "BUCKET_NAME ='winged-tower-295515-bucket'\n",
    "\n",
    "!gsutil mb gs://$BUCKET_NAME/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘crystal_training’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir crystal_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch ./crystal_training/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigQuery API Client Libraries\n",
    "Setting up authentication for BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the service account.\n",
    "# https://cloud.google.com/bigquery/docs/reference/libraries#command-line\n",
    "\n",
    "# !gcloud iam service-accounts create crystal_service_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grant permissions to the service account\n",
    "# !gcloud projects add-iam-policy-binding project winged-tower-295515 --member=\"serviceAccount:crystal_service_acc@winged-tower-295515.iam.gserviceaccount.com\" --role=\"owner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the key file. \n",
    "\n",
    "# !gcloud iam service-accounts keys create key_file_bq_crystal.json --iam-account=crystal_service_acc@winged-tower-295515.iam.gserviceaccount.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Training Job\n",
    "Reading the data from BigQuery and Exploring Dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./crystal_training/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./crystal_training/train.py\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import  recall_score, precision_score,accuracy_score, average_precision_score\n",
    "\n",
    "import google.cloud.bigquery.magics\n",
    "google.cloud.bigquery.magics.context.use_bqstorage_api = True\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "import pickle\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "#create the BigQuery client.\n",
    "client_bq = bigquery.Client()\n",
    "\n",
    "# Running queries\n",
    "\n",
    "dataset_query=\"\"\"\n",
    "SELECT\n",
    "  fullVisitorId, date, \n",
    "  visitStartTime, \n",
    "  visitNumber,\n",
    "  IF(totals.transactions IS NULL, 0, 1) AS purchase,  \n",
    "  \n",
    "  COUNTIF(IF(totals.transactions IS NULL, FALSE, TRUE))\n",
    "  OVER (\n",
    "    PARTITION BY fullVisitorId \n",
    "    ORDER BY visitStartTime\n",
    "    RANGE BETWEEN CURRENT ROW AND 2592000 FOLLOWING\n",
    "  ) AS total_purchases_next30days,\n",
    "  \n",
    "  IFNULL(totals.bounces, 0) AS bounces,\n",
    "  IFNULL(totals.hits, 0) AS hits,\n",
    "  IFNULL(totals.pageviews, 0) AS pageviews,\n",
    "  IFNULL(totals.timeOnSite, 0) AS time_on_site,\n",
    "  IFNULL(totals.visits, 0) AS visits_interaction,\n",
    "\n",
    "  device.isMobile AS is_mobile,\n",
    "  trafficSource.isTrueDirect AS is_source_direct,\n",
    "  IFNULL(geoNetwork.country, \"\") AS country,\n",
    "  channelGrouping\n",
    "\n",
    "\n",
    "FROM\n",
    "  `bigquery-public-data.google_analytics_sample.ga_sessions_*`\n",
    "WHERE\n",
    "  _TABLE_SUFFIX BETWEEN '20160801' AND '20170731'\"\"\"\n",
    "\n",
    "\n",
    "# Make an API request.\n",
    "query_job = client_bq.query(dataset_query)\n",
    "records = [dict(row) for row in query_job]\n",
    "sample_df= pd.DataFrame(records)\n",
    "\n",
    "# Preprocess\n",
    "label= sample_df['total_purchases_next30days']>0\n",
    "sample_df.insert(7,'label',label)\n",
    "\n",
    "sample_df.is_source_direct.replace(to_replace= np.nan, value= False, inplace=True)\n",
    "\n",
    "sample_df = pd.get_dummies(sample_df, columns=['channelGrouping'], prefix='channelGrouping_type')\n",
    "sample_df.drop(columns=['channelGrouping_type_(Other)'], inplace=True)\n",
    "\n",
    "#Split the data to trainset and testset\n",
    "y= sample_df['label']\n",
    "X= sample_df.drop(columns=['label','purchase','total_purchases_next30days','fullVisitorId','visitStartTime','date'], inplace=False)\n",
    "X_trainVal, X_test, y_trainVal, y_test = train_test_split(X, y, test_size=0.20, random_state=42, shuffle= True, stratify= y)\n",
    "\n",
    "\n",
    "# balance the trainingset with manual UnderSampling\n",
    "\n",
    "Xy_trainVal_unblc = pd.concat([X_trainVal, y_trainVal], axis = 1) \n",
    "Xy_trainVal_unblc.reset_index(inplace=True, drop=True) \n",
    "\n",
    "pos_index = Xy_trainVal_unblc[Xy_trainVal_unblc['label']==1].index\n",
    "positive_class= Xy_trainVal_unblc.iloc[pos_index].copy()\n",
    "pos_len = len(positive_class)\n",
    "#remove positives\n",
    "Xy_trainVal_unblc.drop(pos_index, inplace=True)\n",
    "neg_len = len(Xy_trainVal_unblc)\n",
    "\n",
    "neg_coefficient = 1 \n",
    "\n",
    "#Return a random sample of items from an axis of object.\n",
    "negative_class = Xy_trainVal_unblc.sample(n= pos_len, replace='False', random_state = 42)#.reset_index(drop=True)\n",
    "# balanced_df= pd.concat([positive_class, negative_class],ignore_index=True)\n",
    "\n",
    "Xy_trainVal_blc= pd.concat([positive_class, negative_class],ignore_index=True)\n",
    "\n",
    "# Just shuffling\n",
    "Xy_trainVal_blc = shuffle(Xy_trainVal_blc,  random_state=42)\n",
    "Xy_trainVal_blc = shuffle(Xy_trainVal_blc,  random_state=1)\n",
    "Xy_trainVal_blc = shuffle(Xy_trainVal_blc,  random_state=5)\n",
    "Xy_trainVal_blc = shuffle(Xy_trainVal_blc,  random_state=10)\n",
    "Xy_trainVal_blc.reset_index(inplace=True, drop=True) \n",
    "\n",
    "y_trainVal_blc = Xy_trainVal_blc['label'].copy()\n",
    "y_trainVal_blc = pd.DataFrame(y_trainVal_blc, columns=['label'])\n",
    "X_trainVal_blc = Xy_trainVal_blc.drop(columns=['label'], inplace=False)\n",
    "#end of balancing\n",
    "\n",
    "#list of all countries in the training set\n",
    "all_countries_array= X_trainVal_blc['country'].unique()\n",
    "all_countries = set(all_countries_array)\n",
    "\n",
    "# find the list of counrtries based on the number of users who have made a purchase in the next 30 days.\n",
    "purchased_countries = X_trainVal_blc[y_trainVal_blc['label']==1]['country'].value_counts()\n",
    "# purchased_countries is a seri type. we need its indices = countries' names \n",
    "\n",
    "# just top 10% countries: round(0.1*len(all_countries))\n",
    "top_countries_series = purchased_countries.index[0:round(0.1*len(all_countries))]\n",
    "top_countries = set(top_countries_series)\n",
    "\n",
    "#replace other countries in trainset\n",
    "other_countries_in_trainset = list(all_countries - top_countries)\n",
    "\n",
    "X_trainVal_blc.replace(to_replace= other_countries_in_trainset, value='others', inplace=True)\n",
    "\n",
    "#replace other countries in trainset\n",
    "all_countries_array= X_test['country'].unique()\n",
    "all_countries_test = set(all_countries_array)\n",
    "other_countries_in_testset = list(all_countries_test - top_countries)\n",
    "\n",
    "X_test.replace(to_replace= other_countries_in_testset, value='others', inplace=True)\n",
    "\n",
    "X_trainVal_blc = pd.get_dummies(X_trainVal_blc, columns=['country'], prefix='country_is')\n",
    "X_trainVal_blc.drop(columns=['country_is_others'], inplace=True)\n",
    "\n",
    "X_test = pd.get_dummies(X_test, columns=['country'], prefix='country_is')\n",
    "X_test.drop(columns=['country_is_others'], inplace=True)\n",
    "\n",
    "\n",
    "# ML Model\n",
    "\n",
    "y_trainVal_blc = y_trainVal_blc.astype('int')\n",
    "y_test = y_test.astype('int')\n",
    "\n",
    "\n",
    "#Random Forest\n",
    "param_grid = {'n_estimators':[1000], 'criterion': ['gini'], 'min_samples_leaf':[10],\n",
    "              'min_samples_split': [100], 'max_features':['sqrt'],\n",
    "              'class_weight':['balanced'], 'random_state':[0], 'bootstrap':[True], 'oob_score':[True]}\n",
    "\n",
    "\n",
    "cv_scoring = {'average_precision_PR_AUC':'average_precision', 'AUC': 'roc_auc','recall':'recall', 'precision':'precision','accuracy':'accuracy'}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid= param_grid, cv=5, scoring= cv_scoring, \n",
    "                    refit='average_precision_PR_AUC', return_train_score=True, n_jobs= -1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(X_trainVal_blc, y_trainVal_blc)\n",
    "                         \n",
    "rf_refit = grid.best_estimator_.fit(X_trainVal_blc,y_trainVal_blc)\n",
    "\n",
    "#-----------------------------\n",
    "# XGBClassifier\n",
    "# param_grid = {'max_depth': [3], 'n_estimators': [1200], 'learning_rate': [ 0.1],\n",
    "#               'gamma': [ 1],'min_child_weight': [1], 'subsample': [0.6],\n",
    "#               'colsample_bytree': [0.6],'random_state':[0]}\n",
    "\n",
    "# cv_scoring = {'average_precision_PR_AUC':'average_precision', 'AUC': 'roc_auc','recall':'recall', 'precision':'precision','accuracy':'accuracy'}\n",
    "\n",
    "# xgb = XGBClassifier(objective= 'binary:logistic',seed=0)\n",
    "\n",
    "# grid_x = GridSearchCV(xgb, param_grid= param_grid, cv=3, scoring= cv_scoring, \n",
    "#                     refit='average_precision_PR_AUC', return_train_score=True, n_jobs= -1, verbose=1)\n",
    "\n",
    "# grid_result = grid_x.fit(X_trainVal_blc, y_trainVal_blc)\n",
    "                         \n",
    "# xgb_refit = grid_x.best_estimator_.fit(X_trainVal_blc,y_trainVal_blc)\n",
    "#---------------------------\n",
    "\n",
    "# Create the model file\n",
    "# It is required to name the model file \"model.pkl\" if you are using pickle\n",
    "model_filename = \"model.pkl\"\n",
    "with open(model_filename, \"wb\") as model_file:\n",
    "    pickle.dump(rf_refit, model_file)\n",
    "\n",
    "# Upload the model to Cloud Storage\n",
    "bucket_name = 'winged-tower-295515-bucket'\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(model_filename)\n",
    "blob.upload_from_filename(model_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Define a timestamped job name\n",
    "JOB_NAME = \"crystal_training_{}\".format(int(time.time()))\n",
    "\n",
    "# JOB_NAME = \"job_training_{}\".format(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [crystal_training_1608014653] submitted successfully.\n",
      "INFO\t2020-12-15 06:44:29 +0000\tservice\t\tValidating job requirements...\n",
      "INFO\t2020-12-15 06:44:29 +0000\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2020-12-15 06:44:30 +0000\tservice\t\tJob crystal_training_1608014653 is queued.\n",
      "INFO\t2020-12-15 06:44:31 +0000\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2020-12-15 06:47:12 +0000\tservice\t\tWaiting for training program to start.\n",
      "INFO\t2020-12-15 06:47:12 +0000\tservice\t\tJob is preparing.\n",
      "INFO\t2020-12-15 06:52:21 +0000\tmaster-replica-0\t\tRunning task with arguments: --cluster={\"chief\": [\"cmle-training-master-34828f3dd9-0:2222\"]} --task={\"type\": \"chief\", \"index\": 0} --job={\n",
      "INFO\t2020-12-15 06:52:21 +0000\tmaster-replica-0\t\t  \"package_uris\": [\"gs://winged-tower-295515-bucket/crystal_job_dir/packages/3589a21b146763b8de17ee39e7e1033387e95bc49eff0d066f5088d4cf76ca0a/crystal_training-0.0.0.tar.gz\"],\n",
      "INFO\t2020-12-15 06:52:21 +0000\tmaster-replica-0\t\t  \"python_module\": \"crystal_training.train\",\n",
      "INFO\t2020-12-15 06:52:21 +0000\tmaster-replica-0\t\t  \"args\": [\"--bucket-name\", \"winged-tower-295515-bucket\"],\n",
      "INFO\t2020-12-15 06:52:21 +0000\tmaster-replica-0\t\t  \"region\": \"us-central1\",\n",
      "INFO\t2020-12-15 06:52:21 +0000\tmaster-replica-0\t\t  \"runtime_version\": \"2.3\",\n",
      "INFO\t2020-12-15 06:52:21 +0000\tmaster-replica-0\t\t  \"job_dir\": \"gs://winged-tower-295515-bucket/crystal_job_dir\",\n",
      "INFO\t2020-12-15 06:52:21 +0000\tmaster-replica-0\t\t  \"python_version\": \"3.5\"\n",
      "INFO\t2020-12-15 06:52:21 +0000\tmaster-replica-0\t\t}\n",
      "INFO\t2020-12-15 06:52:27 +0000\tmaster-replica-0\t\tRunning module crystal_training.train.\n",
      "INFO\t2020-12-15 06:52:27 +0000\tmaster-replica-0\t\tDownloading the package: gs://winged-tower-295515-bucket/crystal_job_dir/packages/3589a21b146763b8de17ee39e7e1033387e95bc49eff0d066f5088d4cf76ca0a/crystal_training-0.0.0.tar.gz\n",
      "INFO\t2020-12-15 06:52:27 +0000\tmaster-replica-0\t\tRunning command: gsutil -q cp gs://winged-tower-295515-bucket/crystal_job_dir/packages/3589a21b146763b8de17ee39e7e1033387e95bc49eff0d066f5088d4cf76ca0a/crystal_training-0.0.0.tar.gz crystal_training-0.0.0.tar.gz\n",
      "INFO\t2020-12-15 06:52:28 +0000\tmaster-replica-0\t\tInstalling the package: gs://winged-tower-295515-bucket/crystal_job_dir/packages/3589a21b146763b8de17ee39e7e1033387e95bc49eff0d066f5088d4cf76ca0a/crystal_training-0.0.0.tar.gz\n",
      "INFO\t2020-12-15 06:52:28 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps crystal_training-0.0.0.tar.gz\n",
      "INFO\t2020-12-15 06:52:29 +0000\tmaster-replica-0\t\tProcessing ./crystal_training-0.0.0.tar.gz\n",
      "INFO\t2020-12-15 06:52:30 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: crystal-training\n",
      "INFO\t2020-12-15 06:52:30 +0000\tmaster-replica-0\t\t  Building wheel for crystal-training (setup.py): started\n",
      "INFO\t2020-12-15 06:52:30 +0000\tmaster-replica-0\t\t  Building wheel for crystal-training (setup.py): finished with status 'done'\n",
      "INFO\t2020-12-15 06:52:30 +0000\tmaster-replica-0\t\t  Created wheel for crystal-training: filename=crystal_training-0.0.0-py3-none-any.whl size=3940 sha256=f7ed45e450ae9aa7f430e5a27376d12aca939d14a05e0cc6816945cb521600b9\n",
      "INFO\t2020-12-15 06:52:30 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/00/b7/b6/d9f1a8e6335f9d8d61d62950ff5d5307a52cee04140a859e5d\n",
      "INFO\t2020-12-15 06:52:30 +0000\tmaster-replica-0\t\tSuccessfully built crystal-training\n",
      "INFO\t2020-12-15 06:52:30 +0000\tmaster-replica-0\t\tInstalling collected packages: crystal-training\n",
      "INFO\t2020-12-15 06:52:30 +0000\tmaster-replica-0\t\tSuccessfully installed crystal-training-0.0.0\n",
      "INFO\t2020-12-15 06:52:31 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user crystal_training-0.0.0.tar.gz\n",
      "INFO\t2020-12-15 06:52:31 +0000\tmaster-replica-0\t\tProcessing ./crystal_training-0.0.0.tar.gz\n",
      "INFO\t2020-12-15 06:52:32 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: crystal-training\n",
      "INFO\t2020-12-15 06:52:32 +0000\tmaster-replica-0\t\t  Building wheel for crystal-training (setup.py): started\n",
      "INFO\t2020-12-15 06:52:32 +0000\tmaster-replica-0\t\t  Building wheel for crystal-training (setup.py): finished with status 'done'\n",
      "INFO\t2020-12-15 06:52:32 +0000\tmaster-replica-0\t\t  Created wheel for crystal-training: filename=crystal_training-0.0.0-py3-none-any.whl size=3940 sha256=d6b085207c85b7408706e2e38016a0462d99d8ab4c0a700670586442ded24d8b\n",
      "INFO\t2020-12-15 06:52:32 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/00/b7/b6/d9f1a8e6335f9d8d61d62950ff5d5307a52cee04140a859e5d\n",
      "INFO\t2020-12-15 06:52:32 +0000\tmaster-replica-0\t\tSuccessfully built crystal-training\n",
      "INFO\t2020-12-15 06:52:34 +0000\tmaster-replica-0\t\tInstalling collected packages: crystal-training\n",
      "INFO\t2020-12-15 06:52:34 +0000\tmaster-replica-0\t\t  Attempting uninstall: crystal-training\n",
      "INFO\t2020-12-15 06:52:34 +0000\tmaster-replica-0\t\t    Found existing installation: crystal-training 0.0.0\n",
      "INFO\t2020-12-15 06:52:34 +0000\tmaster-replica-0\t\t    Uninstalling crystal-training-0.0.0:\n",
      "INFO\t2020-12-15 06:52:34 +0000\tmaster-replica-0\t\t      Successfully uninstalled crystal-training-0.0.0\n",
      "INFO\t2020-12-15 06:52:34 +0000\tmaster-replica-0\t\tSuccessfully installed crystal-training-0.0.0\n",
      "INFO\t2020-12-15 06:52:34 +0000\tmaster-replica-0\t\tRunning command: python3 -m crystal_training.train --bucket-name winged-tower-295515-bucket --job-dir gs://winged-tower-295515-bucket/crystal_job_dir\n",
      "INFO\t2020-12-15 06:52:36 +0000\tmaster-replica-0\t\tThis service is instrumented using OpenTelemetry.OpenTelemetry could not be imported; pleaseadd opentelemetry-api and opentelemetry-instrumentationpackages in order to get BigQuery Tracing data.\n",
      "INFO\t2020-12-15 06:52:44 +0000\tservice\t\tJob is running.\n",
      "INFO\t2020-12-15 06:54:27 +0000\tmaster-replica-0\t\tFitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "ERROR\t2020-12-15 06:54:27 +0000\tmaster-replica-0\t\t/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:4385: SettingWithCopyWarning: \n",
      "ERROR\t2020-12-15 06:54:27 +0000\tmaster-replica-0\t\tA value is trying to be set on a copy of a slice from a DataFrame\n",
      "ERROR\t2020-12-15 06:54:27 +0000\tmaster-replica-0\t\tSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "ERROR\t2020-12-15 06:54:27 +0000\tmaster-replica-0\t\t  method=method,\n",
      "ERROR\t2020-12-15 06:54:27 +0000\tmaster-replica-0\t\t[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "ERROR\t2020-12-15 06:56:32 +0000\tmaster-replica-0\t\t/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "ERROR\t2020-12-15 06:56:32 +0000\tmaster-replica-0\t\t  estimator.fit(X_train, y_train, **fit_params)\n",
      "ERROR\t2020-12-15 06:56:32 +0000\tmaster-replica-0\t\t/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "ERROR\t2020-12-15 06:56:32 +0000\tmaster-replica-0\t\t  estimator.fit(X_train, y_train, **fit_params)\n",
      "ERROR\t2020-12-15 06:56:32 +0000\tmaster-replica-0\t\t/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "ERROR\t2020-12-15 06:56:32 +0000\tmaster-replica-0\t\t  estimator.fit(X_train, y_train, **fit_params)\n",
      "ERROR\t2020-12-15 06:56:32 +0000\tmaster-replica-0\t\t/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "ERROR\t2020-12-15 06:56:32 +0000\tmaster-replica-0\t\t  estimator.fit(X_train, y_train, **fit_params)\n",
      "ERROR\t2020-12-15 06:56:32 +0000\tmaster-replica-0\t\t/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "ERROR\t2020-12-15 06:56:32 +0000\tmaster-replica-0\t\t  estimator.fit(X_train, y_train, **fit_params)\n",
      "ERROR\t2020-12-15 06:56:33 +0000\tmaster-replica-0\t\t[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.2min finished\n",
      "ERROR\t2020-12-15 06:56:33 +0000\tmaster-replica-0\t\t/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "ERROR\t2020-12-15 06:56:33 +0000\tmaster-replica-0\t\t  self.best_estimator_.fit(X, y, **fit_params)\n",
      "ERROR\t2020-12-15 06:56:33 +0000\tmaster-replica-0\t\t/root/.local/lib/python3.7/site-packages/crystal_training/train.py:159: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "ERROR\t2020-12-15 06:56:33 +0000\tmaster-replica-0\t\t  rf_refit = grid.best_estimator_.fit(X_trainVal_blc,y_trainVal_blc)\n",
      "INFO\t2020-12-15 06:56:34 +0000\tmaster-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2020-12-15 06:56:34 +0000\tmaster-replica-0\t\tClean up finished.\n",
      "INFO\t2020-12-15 06:56:34 +0000\tmaster-replica-0\t\tTask completed successfully.\n",
      "INFO\t2020-12-15 06:56:45 +0000\tservice\t\tTearing down training program.\n",
      "INFO\t2020-12-15 06:57:26 +0000\tservice\t\tFinished tearing down training program.\n",
      "INFO\t2020-12-15 06:57:27 +0000\tservice\t\tJob completed successfully.\n",
      "endTime: '2020-12-15T06:56:45'\n",
      "jobId: crystal_training_1608014653\n",
      "startTime: '2020-12-15T06:52:44'\n",
      "state: SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "# Submit the training job:\n",
    "!gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --job-dir gs://$BUCKET_NAME/crystal_job_dir \\\n",
    "  --package-path ./crystal_training \\\n",
    "  --module-name crystal_training.train \\\n",
    "  --region us-central1 \\\n",
    "  --runtime-version=2.3 \\\n",
    "  --python-version=3.5 \\\n",
    "  --scale-tier BASIC \\\n",
    "  --stream-logs \\\n",
    "  -- \\\n",
    "  --bucket-name $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify model file in Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://winged-tower-295515-bucket/imbalanced_learn-0.7.0-py3-none-any.whl\n",
      "gs://winged-tower-295515-bucket/model.pkl\n",
      "gs://winged-tower-295515-bucket/crystal_job_dir/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://$BUCKET_NAME/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"CrystalPredictorModel\"\n",
    "VERSION_NAME = \"crystal_predictor_{}\".format(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://ml.googleapis.com/]\n",
      "Created ml engine model [projects/winged-tower-295515/models/CrystalPredictorModel].\n"
     ]
    }
   ],
   "source": [
    "# Create the model in AI Platform:\n",
    "\n",
    "!gcloud ai-platform models create $MODEL_NAME --regions us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://ml.googleapis.com/]\n",
      "Creating version (this might take a few minutes)......done.                    \n"
     ]
    }
   ],
   "source": [
    "# Create a version that points to your model file in Cloud Storage:\n",
    "\n",
    "!gcloud ai-platform versions create $VERSION_NAME \\\n",
    "  --model=$MODEL_NAME \\\n",
    "  --framework=scikit-learn \\\n",
    "  --origin=gs://$BUCKET_NAME/ \\\n",
    "  --python-version=3.7 \\\n",
    "  --runtime-version=2.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions\n",
    "## Format data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a name for the input file\n",
    "INPUT_FILE = \"./crystal_training/input.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./crystal_training/input.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $INPUT_FILE\n",
    "{\n",
    "    \"instances\": [\n",
    "        {\"visitNumber\":1,\"bounces\":1,\"hits\":1,\"pageviews\":1,\"time_on_site\":0,\"visits_interaction\":1,\"is_mobile\":true,\"is_source_direct\":false,\"channelGrouping_type_Affiliates\":0,\"channelGrouping_type_Direct\":0,\"channelGrouping_type_Display\":0,\"channelGrouping_type_Organic Search\":1,\"channelGrouping_type_Paid Search\":0,\"channelGrouping_type_Referral\":0,\"channelGrouping_type_Social\":0,\"country_is_Canada\":0,\"country_is_Chile\":0,\"country_is_Hong Kong\":0,\"country_is_Indonesia\":0,\"country_is_Japan\":0,\"country_is_Singapore\":0,\"country_is_Switzerland\":0,\"country_is_Thailand\":0,\"country_is_United Kingdom\":0,\"country_is_United States\":1,\"country_is_Venezuela\":0},\n",
    "        {\"visitNumber\":1,\"bounces\":0,\"hits\":7,\"pageviews\":7,\"time_on_site\":128,\"visits_interaction\":1,\"is_mobile\":true,\"is_source_direct\":true,\"channelGrouping_type_Affiliates\":0,\"channelGrouping_type_Direct\":1,\"channelGrouping_type_Display\":0,\"channelGrouping_type_Organic Search\":0,\"channelGrouping_type_Paid Search\":0,\"channelGrouping_type_Referral\":0,\"channelGrouping_type_Social\":0,\"country_is_Canada\":0,\"country_is_Chile\":0,\"country_is_Hong Kong\":0,\"country_is_Indonesia\":0,\"country_is_Japan\":0,\"country_is_Singapore\":0,\"country_is_Switzerland\":0,\"country_is_Thailand\":0,\"country_is_United Kingdom\":1,\"country_is_United States\":0,\"country_is_Venezuela\":0}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./crystal_training/input.json\n"
     ]
    }
   ],
   "source": [
    "# %%writefile $INPUT_FILE\n",
    "# {\n",
    "#     \"instances\": [\n",
    "#         [1, 0, 16, 11, 246, 1, True, False, 0, 1, 0, 0 ,0, 0, 0 ,0 ,0, 0 ,0 ,0, 0, 0, 0, 0, 1, 0]\n",
    "#     ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send the online prediction request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://ml.googleapis.com/]\n",
      "{\n",
      "  \"error\": \"Prediction failed: Exception during sklearn prediction: float() argument must be a string or a number, not 'dict'\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform predict --model $MODEL_NAME --version \\\n",
    "  $VERSION_NAME --json-request $INPUT_FILE\n",
    "\n",
    "# !gcloud ai-platform local predict --model-dir 'gs://winged-tower-bucket/job_dir/packages/c85e323f4610e652849111fe246050ac8246c0a3358073f7f2a2352eb76776de/Training-0.0.0.tar.gz'  \\\n",
    "#   --json-instances $INPUT_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[1mNAME\u001b[m\n",
      "    gcloud ai-platform predict - run AI Platform online prediction\n",
      "\n",
      "\u001b[m\u001b[1mSYNOPSIS\u001b[m\n",
      "    \u001b[1mgcloud ai-platform predict\u001b[m \u001b[1m--model\u001b[m=\u001b[4mMODEL\u001b[m\n",
      "        (\u001b[1m--json-instances\u001b[m=\u001b[4mJSON_INSTANCES\u001b[m | \u001b[1m--json-request\u001b[m=\u001b[4mJSON_REQUEST\u001b[m\n",
      "          | \u001b[1m--text-instances\u001b[m=\u001b[4mTEXT_INSTANCES\u001b[m) [\u001b[1m--region\u001b[m=\u001b[4mREGION\u001b[m]\n",
      "        [\u001b[1m--signature-name\u001b[m=\u001b[4mSIGNATURE_NAME\u001b[m] [\u001b[1m--version\u001b[m=\u001b[4mVERSION\u001b[m]\n",
      "        [\u001b[4mGCLOUD_WIDE_FLAG ...\u001b[m]\n",
      "\n",
      "\u001b[m\u001b[1mDESCRIPTION\u001b[m\n",
      "    \u001b[1mgcloud ai-platform predict\u001b[m sends a prediction request to AI Platform for\n",
      "    the given instances. This command will read up to 100 instances, though the\n",
      "    service itself will accept instances up to the payload limit size\n",
      "    (currently, 1.5MB). If you are predicting on more instances, you should use\n",
      "    batch prediction via\n",
      "\n",
      "        $ gcloud ai-platform jobs submit prediction.\n",
      "\n",
      "\u001b[m\u001b[1mREQUIRED FLAGS\u001b[m\n",
      "     \u001b[1m--model\u001b[m=\u001b[4mMODEL\u001b[m\n",
      "        Name of the model.\n",
      "\n",
      "     Exactly one of these must be specified:\n",
      "\n",
      "       \u001b[1m--json-instances\u001b[m=\u001b[4mJSON_INSTANCES\u001b[m\n",
      "          Path to a local file from which instances are read. Instances are in\n",
      "          JSON format; newline delimited.\n",
      "\n",
      "          An example of the JSON instances file:\n",
      "\n",
      "              {\"images\": [0.0, ..., 0.1], \"key\": 3}\n",
      "              {\"images\": [0.0, ..., 0.1], \"key\": 2}\n",
      "              ...\n",
      "\n",
      "          This flag accepts \"-\" for stdin.\n",
      "\n",
      "       \u001b[1m--json-request\u001b[m=\u001b[4mJSON_REQUEST\u001b[m\n",
      "          Path to a local file containing the body of JSON request.\n",
      "\n",
      "          An example of a JSON request:\n",
      "\n",
      "              {\n",
      "                \"instances\": [\n",
      "                  {\"x\": [1, 2], \"y\": [3, 4]},\n",
      "                  {\"x\": [-1, -2], \"y\": [-3, -4]}\n",
      "                ]\n",
      "              }\n",
      "\n",
      "          This flag accepts \"-\" for stdin.\n",
      "\n",
      "       \u001b[1m--text-instances\u001b[m=\u001b[4mTEXT_INSTANCES\u001b[m\n",
      "          Path to a local file from which instances are read. Instances are in\n",
      "          UTF-8 encoded text format; newline delimited.\n",
      "\n",
      "          An example of the text instances file:\n",
      "\n",
      "              107,4.9,2.5,4.5,1.7\n",
      "              100,5.7,2.8,4.1,1.3\n",
      "              ...\n",
      "\n",
      "          This flag accepts \"-\" for stdin.\n",
      "\n",
      "\u001b[m\u001b[1mOPTIONAL FLAGS\u001b[m\n",
      "     \u001b[1m--region\u001b[m=\u001b[4mREGION\u001b[m\n",
      "        Google Cloud region of the regional endpoint to use for this command.\n",
      "        If unspecified, the command uses the global endpoint of the AI Platform\n",
      "        Training and Prediction API.\n",
      "\n",
      "        Learn more about regional endpoints and see a list of available\n",
      "        regions:\n",
      "        https://cloud.google.com/ai-platform/prediction/docs/regional-endpoints\n",
      "\n",
      "        \u001b[4mREGION\u001b[m must be one of: \u001b[1masia-east1\u001b[m, \u001b[1masia-northeast1\u001b[m, \u001b[1masia-southeast1\u001b[m,\n",
      "        \u001b[1maustralia-southeast1\u001b[m, \u001b[1meurope-west1\u001b[m, \u001b[1meurope-west2\u001b[m, \u001b[1meurope-west3\u001b[m,\n",
      "        \u001b[1meurope-west4\u001b[m, \u001b[1mnorthamerica-northeast1\u001b[m, \u001b[1mus-central1\u001b[m, \u001b[1mus-east1\u001b[m, \u001b[1mus-east4\u001b[m,\n",
      "        \u001b[1mus-west1\u001b[m.\n",
      "\n",
      "     \u001b[1m--signature-name\u001b[m=\u001b[4mSIGNATURE_NAME\u001b[m\n",
      "        Name of the signature defined in the SavedModel to use for this job.\n",
      "        Defaults to DEFAULT_SERVING_SIGNATURE_DEF_KEY in\n",
      "        https://www.tensorflow.org/api_docs/python/tf/compat/v1/saved_model/signature_constants,\n",
      "        which is \"serving_default\". Only applies to TensorFlow models.\n",
      "\n",
      "     \u001b[1m--version\u001b[m=\u001b[4mVERSION\u001b[m\n",
      "        Model version to be used.\n",
      "\n",
      "        If unspecified, the default version of the model will be used. To list\n",
      "        model versions run\n",
      "\n",
      "            $ gcloud ai-platform versions list\n",
      "\n",
      "\u001b[m\u001b[1mGCLOUD WIDE FLAGS\u001b[m\n",
      "    These flags are available to all commands: --account, --billing-project,\n",
      "    --configuration, --flags-file, --flatten, --format, --help,\n",
      "    --impersonate-service-account, --log-http, --project, --quiet,\n",
      "    --trace-token, --user-output-enabled, --verbosity.\n",
      "\n",
      "    Run \u001b[1m$ gcloud help\u001b[m for details.\n",
      "\n",
      "\u001b[m\u001b[1mNOTES\u001b[m\n",
      "    These variants are also available:\n",
      "\n",
      "        $ gcloud alpha ai-platform predict\n",
      "        $ gcloud beta ai-platform predict\n",
      "\n",
      "\u001b[m"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform predict --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch prediction\n",
    "read the last day of data as a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the BigQuery client.\n",
    "client_bq = bigquery.Client()\n",
    "\n",
    "# Running queries\n",
    "\n",
    "dataset_query=\"\"\"SELECT\n",
    "  fullVisitorId, date, \n",
    "  visitStartTime, \n",
    "  visitNumber,\n",
    "  IF(totals.transactions IS NULL, 0, 1) AS purchase,  \n",
    "  \n",
    "  COUNTIF(IF(totals.transactions IS NULL, FALSE, TRUE))\n",
    "  OVER (\n",
    "    PARTITION BY fullVisitorId \n",
    "    ORDER BY visitStartTime\n",
    "    RANGE BETWEEN CURRENT ROW AND 2592000 FOLLOWING\n",
    "  ) AS total_purchases_next30days,\n",
    "  \n",
    "  IFNULL(totals.bounces, 0) AS bounces,\n",
    "  IFNULL(totals.hits, 0) AS hits,\n",
    "  IFNULL(totals.pageviews, 0) AS pageviews,\n",
    "  IFNULL(totals.timeOnSite, 0) AS time_on_site,\n",
    "  IFNULL(totals.visits, 0) AS visits_interaction,\n",
    "\n",
    "  device.isMobile AS is_mobile,\n",
    "  trafficSource.isTrueDirect AS is_source_direct,\n",
    "  IFNULL(geoNetwork.country, \"\") AS country,\n",
    "  channelGrouping\n",
    "  \n",
    "FROM\n",
    "  `bigquery-public-data.google_analytics_sample.ga_sessions_20170801`\"\"\"\n",
    "\n",
    "\n",
    " # Make an API request.\n",
    "query_job = client_bq.query(dataset_query)\n",
    "records = [dict(row) for row in query_job]\n",
    "batch_df= pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2556, 15)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Batch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label= batch_df['total_purchases_next30days']>0\n",
    "batch_df.insert(7,'label',label)\n",
    "\n",
    "# Replace NAN values with False\n",
    "batch_df.is_source_direct.replace(to_replace= np.nan, value= False, inplace=True)\n",
    "batch_df.is_source_direct.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert categorical columns to dummies\n",
    "batch_df = pd.get_dummies(batch_df, columns=['channelGrouping'], prefix='channelGrouping_type')\n",
    "# batch_df.drop(columns=['channelGrouping_type_(Other)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_batch= batch_df['label']\n",
    "y_batch = y_batch.astype('int')\n",
    "\n",
    "X_batch= batch_df.drop(columns=['label','purchase','total_purchases_next30days','fullVisitorId','visitStartTime','date'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert categorical 'country' column to dummies\n",
    "all_countries_array= X_batch['country'].unique()\n",
    "all_countries_test = set(all_countries_array)\n",
    "\n",
    "top_countries= {'Venezuela','Japan','United Kingdom','Canada','Indonesia','Thailand','Singapore','Chile','United States','Switzerland','Hong Kong'}\n",
    "other_countries_in_testset = list(all_countries_test - top_countries)\n",
    "\n",
    "X_batch.replace(to_replace= other_countries_in_testset, value='others', inplace=True)\n",
    "\n",
    "X_batch = pd.get_dummies(X_batch, columns=['country'], prefix='country_is')\n",
    "X_batch.drop(columns=['country_is_others'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2556 entries, 0 to 2555\n",
      "Data columns (total 26 columns):\n",
      " #   Column                               Non-Null Count  Dtype\n",
      "---  ------                               --------------  -----\n",
      " 0   visitNumber                          2556 non-null   int64\n",
      " 1   bounces                              2556 non-null   int64\n",
      " 2   hits                                 2556 non-null   int64\n",
      " 3   pageviews                            2556 non-null   int64\n",
      " 4   time_on_site                         2556 non-null   int64\n",
      " 5   visits_interaction                   2556 non-null   int64\n",
      " 6   is_mobile                            2556 non-null   bool \n",
      " 7   is_source_direct                     2556 non-null   bool \n",
      " 8   channelGrouping_type_Affiliates      2556 non-null   uint8\n",
      " 9   channelGrouping_type_Direct          2556 non-null   uint8\n",
      " 10  channelGrouping_type_Display         2556 non-null   uint8\n",
      " 11  channelGrouping_type_Organic Search  2556 non-null   uint8\n",
      " 12  channelGrouping_type_Paid Search     2556 non-null   uint8\n",
      " 13  channelGrouping_type_Referral        2556 non-null   uint8\n",
      " 14  channelGrouping_type_Social          2556 non-null   uint8\n",
      " 15  country_is_Canada                    2556 non-null   uint8\n",
      " 16  country_is_Chile                     2556 non-null   uint8\n",
      " 17  country_is_Hong Kong                 2556 non-null   uint8\n",
      " 18  country_is_Indonesia                 2556 non-null   uint8\n",
      " 19  country_is_Japan                     2556 non-null   uint8\n",
      " 20  country_is_Singapore                 2556 non-null   uint8\n",
      " 21  country_is_Switzerland               2556 non-null   uint8\n",
      " 22  country_is_Thailand                  2556 non-null   uint8\n",
      " 23  country_is_United Kingdom            2556 non-null   uint8\n",
      " 24  country_is_United States             2556 non-null   uint8\n",
      " 25  country_is_Venezuela                 2556 non-null   uint8\n",
      "dtypes: bool(2), int64(6), uint8(18)\n",
      "memory usage: 169.9 KB\n"
     ]
    }
   ],
   "source": [
    "X_batch.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"0\":{\"visitNumber\":1,\"bounces\":1,\"hits\":1,\"pageviews\":1,\"time_on_site\":0,\"visits_interaction\":1,\"is_mobile\":true,\"is_source_direct\":false,\"channelGrouping_type_Affiliates\":0,\"channelGrouping_type_Direct\":0,\"channelGrouping_type_Display\":0,\"channelGrouping_type_Organic Search\":1,\"channelGrouping_type_Paid Search\":0,\"channelGrouping_type_Referral\":0,\"channelGrouping_type_Social\":0,\"country_is_Canada\":0,\"country_is_Chile\":0,\"country_is_Hong Kong\":0,\"country_is_Indonesia\":0,\"country_is_Japan\":0,\"country_is_Singapore\":0,\"country_is_Switzerland\":0,\"country_is_Thailand\":0,\"country_is_United Kingdom\":0,\"country_is_United States\":1,\"country_is_Venezuela\":0},\"1\":{\"visitNumber\":1,\"bounces\":0,\"hits\":7,\"pageviews\":7,\"time_on_site\":128,\"visits_interaction\":1,\"is_mobile\":true,\"is_source_direct\":true,\"channelGrouping_type_Affiliates\":0,\"channelGrouping_type_Direct\":1,\"channelGrouping_type_Display\":0,\"channelGrouping_type_Organic Search\":0,\"channelGrouping_type_Paid Search\":0,\"channelGrouping_type_Referral\":0,\"channelGrouping_type_Social\":0,\"country_is_Canada\":0,\"country_is_Chile\":0,\"country_is_Hong Kong\":0,\"country_is_Indonesia\":0,\"country_is_Japan\":0,\"country_is_Singapore\":0,\"country_is_Switzerland\":0,\"country_is_Thailand\":0,\"country_is_United Kingdom\":1,\"country_is_United States\":0,\"country_is_Venezuela\":0},\"2\":{\"visitNumber\":2,\"bounces\":1,\"hits\":1,\"pageviews\":1,\"time_on_site\":0,\"visits_interaction\":1,\"is_mobile\":true,\"is_source_direct\":true,\"channelGrouping_type_Affiliates\":0,\"channelGrouping_type_Direct\":0,\"channelGrouping_type_Display\":0,\"channelGrouping_type_Organic Search\":1,\"channelGrouping_type_Paid Search\":0,\"channelGrouping_type_Referral\":0,\"channelGrouping_type_Social\":0,\"country_is_Canada\":0,\"country_is_Chile\":0,\"country_is_Hong Kong\":0,\"country_is_Indonesia\":0,\"country_is_Japan\":0,\"country_is_Singapore\":0,\"country_is_Switzerland\":0,\"country_is_Thailand\":0,\"country_is_United Kingdom\":0,\"country_is_United States\":1,\"country_is_Venezuela\":0}}'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch[0:3].to_json(orient='index')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
